{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "byDDf6_n3O_T"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the dataset path\n",
    "data_dir = 'Data'\n",
    "\n",
    "# Parameters\n",
    "img_height, img_width = 128, 128  # Resize images to 128x128\n",
    "batch_size = 32\n",
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,   # Normalize pixel values\n",
    "    validation_split=0.2,  # 20% data for validation\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1uTv9K54n7Y",
    "outputId": "aa9955ef-b723-4b8f-fe08-d4944930238b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1710 images belonging to 9 classes.\n",
      "Found 423 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Training and Validation Data\n",
    "train_data = data_gen.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = data_gen.flow_from_directory(\n",
    "    directory=data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91cFPep74uOE",
    "outputId": "82d36623-4c8d-4722-c6ef-9acd36b795d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/balajikartheek/Desktop/Websites/Survailance2/signLanguage/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "classes = 9\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu')\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(classes, activation='softmax')  # 9 output classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vlq9WTlK4z4t"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aS5iTEtW45fT",
    "outputId": "263654ae-c7f1-4e17-d09b-9a50f7ed66a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/balajikartheek/Desktop/Websites/Survailance2/signLanguage/.venv/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 435ms/step - accuracy: 0.1821 - loss: 2.1767 - val_accuracy: 0.4610 - val_loss: 1.5274\n",
      "Epoch 2/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 403ms/step - accuracy: 0.4599 - loss: 1.4670 - val_accuracy: 0.7329 - val_loss: 0.8796\n",
      "Epoch 3/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.6041 - loss: 1.0271 - val_accuracy: 0.7991 - val_loss: 0.6240\n",
      "Epoch 4/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 474ms/step - accuracy: 0.6987 - loss: 0.8322 - val_accuracy: 0.8747 - val_loss: 0.4299\n",
      "Epoch 5/5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 456ms/step - accuracy: 0.7594 - loss: 0.6658 - val_accuracy: 0.8369 - val_loss: 0.4390\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bB1nSFCs47iH",
    "outputId": "d146efc2-9e11-4f24-de22-202294640304"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/balajikartheek/Desktop/Websites/Survailance2/signLanguage/.venv/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 205ms/step - accuracy: 0.8541 - loss: 0.4319\n",
      "Validation Accuracy: 86.52%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the Model\n",
    "# model.save('sign_language_model.h5')\n",
    "\n",
    "# Evaluate the Model\n",
    "test_loss, test_accuracy = model.evaluate(val_data)\n",
    "print(f\"Validation Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('sign_language_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def predict_class(image_path):\n",
    "    img = image.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    predictions = model.predict(img_array)\n",
    "    class_idx = np.argmax(predictions)\n",
    "    class_label = list(train_data.class_indices.keys())[class_idx]\n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zTIkIMtc9PY4",
    "outputId": "19afb999-c018-44ee-f89f-0d51ea99639e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "Predicted Class: Hello\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Example\n",
    "example_image = 'Data/Hello/Image_1729946405.997163.jpg'\n",
    "result = predict_class(example_image)\n",
    "print(f\"Predicted Class: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaDH207r9qU4",
    "outputId": "66fe331d-d075-47ae-fcdc-106457669bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Predicted Class: Victory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Example\n",
    "example_image = 'Data/Victory/Image_1729947769.15842.jpg'\n",
    "result = predict_class(example_image)\n",
    "print(f\"Predicted Class: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEvc5B0gHGRI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
